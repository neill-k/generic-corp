# Market Research & Competitive Analysis
**Date**: January 26, 2026
**Author**: Graham "Gray" Sutton, Data Engineer
**Purpose**: Market validation, competitive pricing analysis, and analytics framework for revenue initiative

---

## Executive Summary

This document provides data-driven insights for AgentHQ's go-to-market strategy, including:
- Competitive landscape analysis
- Pricing benchmarking and recommendations
- Use case validation with market sizing
- Analytics infrastructure requirements
- Key metrics tracking framework

**Key Findings**:
- ‚úÖ Market is validated ($2B+ TAM for AI agent orchestration)
- ‚úÖ Pricing is competitive ($49-$149/mo sweet spot)
- ‚úÖ Visual differentiation is unique in market
- ‚úÖ Infrastructure gaps exist in current solutions
- ‚ö†Ô∏è Need robust analytics from day 1 to optimize conversion

---

## 1. Competitive Landscape Analysis

### Direct Competitors

#### LangGraph (LangChain)
**Website**: langchain.com/langgraph
**Model**: Open source + LangSmith SaaS
**Pricing**:
- LangGraph: Free (open source)
- LangSmith: $39/mo Developer, $199/mo Team, Enterprise custom
- Focus: Tracing, monitoring, evaluation

**Strengths**:
- Massive community (80K+ GitHub stars)
- Comprehensive documentation
- Extensive integrations
- Enterprise adoption

**Weaknesses**:
- Code-first, steep learning curve
- No visual orchestration
- Complex architecture
- Debugging is difficult without LangSmith

**Our Advantage**: Visual-first interface, simpler onboarding, built-in production infrastructure

---

#### CrewAI
**Website**: crewai.com
**Model**: Open source library
**Pricing**: Free (open source), no hosted offering

**Strengths**:
- Role-based agent design (intuitive)
- Simple Python API
- Growing community (15K+ GitHub stars)
- Good documentation

**Weaknesses**:
- CLI/code only, no visualization
- Limited production features
- No hosted option
- Manual infrastructure setup

**Our Advantage**: Visual interface, hosted option, production-ready infrastructure, real-time monitoring

---

#### AutoGPT
**Website**: agpt.co
**Model**: Open source + commercial plans
**Pricing**:
- Free tier: Limited
- Pro: $10/mo
- Team: $30/user/mo

**Strengths**:
- First mover advantage (165K+ GitHub stars)
- Strong brand recognition
- Agent marketplace

**Weaknesses**:
- Autonomous but chaotic
- Limited orchestration control
- Performance issues
- Not production-focused

**Our Advantage**: Controlled orchestration, production reliability, team coordination, enterprise-grade

---

#### Flowise AI
**Website**: flowiseai.com
**Model**: Open source visual builder
**Pricing**: Free (self-hosted), cloud hosting coming

**Strengths**:
- Visual flow builder (drag-and-drop)
- Low-code approach
- Good for prototyping
- Active development

**Weaknesses**:
- Single agent focus (not multi-agent)
- No production infrastructure
- Limited monitoring
- Immature for enterprise

**Our Advantage**: Multi-agent orchestration, production infrastructure, real-time coordination, enterprise features

---

#### n8n (Workflow automation with AI)
**Website**: n8n.io
**Model**: Open source + cloud hosting
**Pricing**:
- Self-hosted: Free
- Starter: $20/mo
- Pro: $50/mo
- Enterprise: Custom

**Strengths**:
- Mature workflow engine
- 400+ integrations
- Visual builder
- Strong community

**Weaknesses**:
- Not AI-agent specific
- Basic AI capabilities
- No Claude Agent SDK
- General workflow tool, not specialized

**Our Advantage**: AI-agent native, Claude Agent SDK, specialized for multi-agent systems, isometric game view

---

### Indirect Competitors

**Traditional Workflow Tools**:
- Zapier, Make (Integromat), Temporal
- Not AI-agent focused, but used for automation

**AI Development Platforms**:
- Hugging Face, Replicate, Modal
- Infrastructure for models, not agent orchestration

**Enterprise AI Platforms**:
- DataRobot, H2O.ai, Databricks
- ML ops, not agent orchestration

---

## 2. Pricing Analysis & Recommendations

### Competitor Pricing Matrix

| Product | Free Tier | Starter | Pro | Enterprise |
|---------|-----------|---------|-----|------------|
| **LangSmith** | 5K traces | $39/mo | $199/mo | Custom |
| **n8n** | Self-host | $20/mo | $50/mo | Custom |
| **AutoGPT** | Limited | $10/mo | $30/user | N/A |
| **Flowise** | Self-host | TBD | TBD | TBD |
| **Generic Corp** | Self-host | **$49/mo** | **$149/mo** | **Custom** |

### Pricing Strategy Validation

**Our Proposed Pricing** (from REVENUE_STRATEGY.md):
```
Free (Self-Hosted): Open-source core, Docker, community support
Starter ($49/mo): Managed cloud, 5 agents, 1K agent-minutes/mo
Pro ($149/mo): 20 agents, 10K agent-minutes/mo, priority support, SSO
Enterprise (Custom): Unlimited, dedicated infra, SLA, compliance
```

**Analysis**: ‚úÖ **Well-Positioned**

**Rationale**:
1. **$49 Starter**: Between n8n ($20) and LangSmith ($39), justified by:
   - Complete infrastructure (not just monitoring)
   - Visual interface (unique value)
   - Claude Agent SDK integration
   - Production-ready from day 1

2. **$149 Pro**: Matches LangSmith's team tier
   - Target: Small teams (5-20 people)
   - Business features (SSO, priority support)
   - Higher resource limits

3. **Enterprise**: Standard SaaS model
   - Custom pricing based on scale
   - Target: $25K-$100K annually
   - Focus on security, compliance, SLA

### Usage-Based Pricing Component

**Recommendation**: Add usage-based API pricing for flexibility

```
API Access (Pay-as-you-go):
- $0.01 per agent-minute
- $0.001 per webhook event
- Volume discount: 20% off at $500+/mo
```

**Benefits**:
- Captures high-volume users
- More predictable for customers with variable workloads
- Common in AI/infrastructure space
- Can generate $500-$5K/mo per customer

---

## 3. Use Case Validation & Market Sizing

### Validated Use Cases (Priority Order)

#### Use Case 1: Customer Support Automation üèÜ
**Market Size**: $15B+ (AI customer service market)
**Target Users**: Startups, SMBs, Enterprises
**Agent Team Example**:
- Ticket Triage Agent (classifies, prioritizes)
- Knowledge Base Agent (searches docs)
- Response Draft Agent (writes replies)
- Escalation Agent (routes to humans)
- Quality Assurance Agent (reviews responses)

**Value Proposition**:
- 70% ticket deflection rate
- 24/7 availability
- Consistent quality
- Visual monitoring dashboard

**Market Validation**:
- Every SaaS company needs this
- Clear ROI calculation
- Existing tools (Zendesk, Intercom) are expensive
- Our solution: $149/mo vs $50K+ for legacy systems

---

#### Use Case 2: Content Creation Pipeline
**Market Size**: $10B+ (content marketing market)
**Target Users**: Marketing agencies, Content teams, Media companies
**Agent Team Example**:
- Research Agent (gathers sources)
- Outline Agent (structures content)
- Writing Agent (drafts copy)
- SEO Agent (optimizes)
- Fact-Check Agent (validates claims)
- Editor Agent (reviews quality)

**Value Proposition**:
- 10x content production speed
- Consistent brand voice
- SEO optimization built-in
- Quality control automated

**Market Validation**:
- Content is bottleneck for most companies
- Freelance writers cost $0.10-$0.50/word
- AI + orchestration = $0.01/word + better quality
- High willingness to pay

---

#### Use Case 3: Code Review & Testing
**Market Size**: $5B+ (DevOps tools market)
**Target Users**: Software teams, Dev agencies
**Agent Team Example**:
- Code Analysis Agent (reviews PRs)
- Security Scanner Agent (finds vulnerabilities)
- Test Generation Agent (writes tests)
- Documentation Agent (updates docs)
- Performance Agent (optimizes code)

**Value Proposition**:
- Faster code reviews
- Higher test coverage
- Automated documentation
- Security best practices

**Market Validation**:
- Every dev team struggles with this
- GitHub Copilot proves market
- Complementary to existing tools
- Developers will pay for time savings

---

#### Use Case 4: Research & Analysis
**Market Size**: $8B+ (market research industry)
**Target Users**: Analysts, Consultants, Researchers
**Agent Team Example**:
- Data Collection Agent (scrapes, gathers)
- Analysis Agent (identifies patterns)
- Synthesis Agent (summarizes findings)
- Visualization Agent (creates charts)
- Report Agent (writes executive summary)

**Value Proposition**:
- Week-long research in hours
- Multiple sources synthesized
- Bias reduction
- Reproducible methodology

**Market Validation**:
- Consultants charge $200-$500/hour
- Market research reports cost $5K-$50K
- Huge time savings = clear ROI
- Academic + enterprise demand

---

#### Use Case 5: Sales & Lead Qualification
**Market Size**: $12B+ (sales automation market)
**Target Users**: Sales teams, B2B companies
**Agent Team Example**:
- Lead Enrichment Agent (gathers data)
- Qualification Agent (scores leads)
- Outreach Agent (personalizes emails)
- Follow-up Agent (manages sequences)
- CRM Agent (updates records)

**Value Proposition**:
- 50% more qualified leads
- Personalization at scale
- Automated follow-up
- Sales team focuses on closing

**Market Validation**:
- Sales automation is proven category
- Tools like Outreach, SalesLoft are $100-$150/user/mo
- Our orchestration adds intelligence
- High LTV customers (sales teams have budget)

---

### TAM/SAM/SOM Analysis

**TAM (Total Addressable Market)**:
- AI development tools market: $10B+ by 2026
- Workflow automation market: $20B+ by 2026
- Combined AI agent orchestration: **~$2B potential**

**SAM (Serviceable Addressable Market)**:
- English-speaking markets (US, UK, EU, APAC)
- Developer/startup focus initially
- **~$500M addressable**

**SOM (Serviceable Obtainable Market)**:
- Year 1 target: 0.1% of SAM
- **~$500K ARR realistic** (aggressive: $1M ARR)
- Requires ~400 paying customers at $100 ARPU

---

## 4. Analytics Infrastructure Requirements

### Phase 1: Foundation (Week 1-2)

**Essential Tracking**:
```
Landing Page Analytics:
- Page views, unique visitors
- Bounce rate, time on page
- CTA click rates
- Waitlist conversion rate
- Source/medium attribution

Recommended Tool: Plausible (privacy-friendly, free self-hosted)
Setup: 1 hour, add script to landing page
```

**User Tracking**:
```
Signup Funnel:
- Signup page views
- Form starts
- Form completions
- Email verification
- First login

Recommended Tool: PostHog (free tier, self-hosted option)
Setup: 2 hours, integrate with signup flow
```

---

### Phase 2: Product Analytics (Week 3-4)

**Key Events to Track**:
```javascript
// Critical conversion events
track('trial_started', {
  user_id, plan, source, timestamp
})

track('first_agent_created', {
  user_id, agent_type, time_to_first_agent
})

track('first_agent_deployed', {
  user_id, deployment_duration, success
})

track('upgrade_to_paid', {
  user_id, plan, mrr, source
})

// Engagement events
track('agent_created', {
  user_id, agent_count, agent_type
})

track('workflow_executed', {
  user_id, workflow_id, duration, success
})

track('dashboard_viewed', {
  user_id, session_duration
})

// Churn signals
track('billing_failed', {
  user_id, plan, amount
})

track('downgrade_request', {
  user_id, from_plan, to_plan, reason
})

track('inactive_7_days', {
  user_id, last_active
})
```

**Implementation**:
- Backend: Add event tracking to key user actions
- Frontend: Track UI interactions
- Webhooks: Stripe events for payment tracking
- Database: Store events for historical analysis

---

### Phase 3: Revenue Analytics (Week 5-6)

**Revenue Dashboard** (Build in-house or use Stripe Dashboard + Spreadsheet):

**Key Metrics**:
```
MRR Tracking:
- Current MRR
- New MRR (from new customers)
- Expansion MRR (upgrades)
- Contraction MRR (downgrades)
- Churn MRR (cancellations)
- Net New MRR

Customer Metrics:
- New customers
- Churned customers
- Net customer change
- Customer count by plan
- Average revenue per customer (ARPU)

Cohort Analysis:
- Month 0 retention: 100%
- Month 1 retention: target 95%
- Month 3 retention: target 85%
- Month 6 retention: target 80%
- Cohort LTV by acquisition month
```

**Tools**:
- Stripe: Built-in revenue reports
- Google Sheets: Custom revenue dashboard
- ChartMogul (future): Advanced MRR analytics ($100/mo when we have budget)

---

### Analytics Data Model

**Core Tables**:
```sql
-- Users
users (
  user_id UUID PRIMARY KEY,
  email VARCHAR,
  plan VARCHAR, -- free, starter, pro, enterprise
  mrr DECIMAL,
  status VARCHAR, -- trial, active, churned
  signup_date TIMESTAMP,
  first_agent_date TIMESTAMP,
  conversion_date TIMESTAMP,
  churn_date TIMESTAMP,
  source VARCHAR,
  created_at TIMESTAMP
)

-- Events
events (
  event_id UUID PRIMARY KEY,
  user_id UUID REFERENCES users,
  event_name VARCHAR,
  properties JSONB,
  timestamp TIMESTAMP,
  created_at TIMESTAMP
)

-- Revenue
revenue_events (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users,
  event_type VARCHAR, -- charge, refund, upgrade, downgrade
  amount DECIMAL,
  plan VARCHAR,
  mrr_delta DECIMAL,
  timestamp TIMESTAMP,
  stripe_event_id VARCHAR,
  created_at TIMESTAMP
)

-- Agent Usage (for usage-based pricing)
agent_usage (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users,
  agent_id UUID,
  agent_minutes DECIMAL,
  webhook_events INTEGER,
  cost DECIMAL,
  period_start DATE,
  period_end DATE,
  created_at TIMESTAMP
)
```

---

## 5. Key Metrics Framework

### North Star Metric
**Metric**: Weekly Active Users (WAU) deploying agents
**Why**: Indicates product value, correlates with retention and conversion

**Target Trajectory**:
- Week 1: 5 WAU
- Week 2: 15 WAU
- Week 3: 30 WAU
- Week 4: 50 WAU
- Week 5: 75 WAU
- Week 6: 100 WAU

---

### Primary Metrics (Review Daily)

**1. Revenue Metrics**
- **MRR**: Current monthly recurring revenue
  - Target Week 6: $5K-$10K
- **Net New MRR**: Weekly MRR growth
  - Target: +$1K-$2K per week after launch
- **ARPU**: Average revenue per paying user
  - Target: $100 (mix of $49 and $149 plans)

**2. Acquisition Metrics**
- **Website Traffic**: Unique visitors per week
  - Week 1: 100, Week 2: 1000, Week 6: 2000+
- **Signup Rate**: Visitors ‚Üí Trial signups
  - Target: 10-20% (aggressive for B2B SaaS)
- **Source Mix**: Track top channels
  - HN, Twitter, GitHub, Reddit, Direct

**3. Activation Metrics**
- **Activation Rate**: Trial ‚Üí First agent deployed
  - Target: 50% (strong activation)
  - Industry benchmark: 30-40%
- **Time to First Agent**: Minutes from signup
  - Target: <30 minutes
  - Faster = better onboarding

**4. Conversion Metrics**
- **Trial ‚Üí Paid**: % of trial users who convert
  - Target: 10% (industry standard)
  - Premium: 15-20% with great onboarding
- **Days to Convert**: Average time
  - Target: 7-14 days
  - Track by plan tier

**5. Retention Metrics**
- **Monthly Churn**: % of customers who cancel
  - Target: <5% (excellent for early stage)
  - Industry: 5-7% is good, <3% is exceptional
- **Net Revenue Retention**: MRR retained + expanded
  - Target: >100% (expansion > churn)
  - Requires upsells and expansion

---

### Secondary Metrics (Review Weekly)

**Engagement**:
- Active users (DAU, WAU, MAU)
- Agents created per user
- Workflows executed per user
- Session duration
- Feature usage breakdown

**Support**:
- Support tickets per customer
- Response time (target: <4 hours)
- Resolution time (target: <24 hours)
- CSAT score (target: >80%)

**Product Health**:
- API error rate (target: <0.1%)
- System uptime (target: 99.9%)
- Page load time (target: <2s)
- Agent execution success rate

**Marketing**:
- GitHub stars growth
- Twitter followers
- Discord members
- Email open rate (target: 25%+)
- Email click rate (target: 3%+)

---

## 6. Competitive Intelligence Process

### Ongoing Monitoring

**Weekly Tasks**:
1. Check competitor pricing pages (screenshots + archive)
2. Monitor competitor GitHub activity (releases, stars, issues)
3. Track competitor social media (announcements, customer feedback)
4. Review competitor job postings (reveals priorities)
5. Test competitor products (free tiers, note changes)

**Tools**:
- [archive.org](https://archive.org): Save snapshots of competitor pages
- [Google Alerts](https://google.com/alerts): Competitor name + "pricing", "funding", "launch"
- [GitHub Watch](https://github.com): Star and watch competitor repos
- [BuiltWith](https://builtwith.com): Track competitor tech stack

**Tracking Sheet**: Update monthly
| Competitor | Pricing Change | Product Updates | Funding News | Our Response |
|------------|---------------|-----------------|--------------|--------------|
| LangChain | - | - | - | - |

---

### Product Hunt & Launch Monitoring

**Watch Launches**:
- AI agent tools
- Workflow automation
- Developer platforms

**Extract Insights**:
- What messaging resonates? (upvotes, comments)
- What objections do users have?
- What features do people ask for?
- What pricing feedback appears?

---

## 7. User Research Plan

### Initial Research (Week 1-2)

**Objective**: Validate problem, solution, and pricing

**Method**: 10 customer development interviews
- 30 minutes each
- AI developers, startup founders, dev agencies
- Record (with permission), transcribe, analyze

**Interview Script**:
```
1. Background (5 min)
   - Tell me about your current project/company
   - How do you use AI agents today?
   - What tools/frameworks do you use?

2. Pain Points (10 min)
   - What's the hardest part about building with AI agents?
   - Tell me about a time when agent debugging was frustrating
   - How do you monitor agents in production?
   - What's missing from current tools?

3. Solution Validation (10 min)
   - [Show demo] What do you think?
   - Would this solve [their pain point]?
   - How would you use this in your workflow?
   - What features are must-haves vs. nice-to-haves?

4. Pricing Validation (3 min)
   - How much do you currently spend on AI/dev tools?
   - What would you expect to pay for this?
   - [Show pricing] What do you think of these tiers?
   - Which plan would you choose?

5. Close (2 min)
   - Would you be interested in early access?
   - Can I follow up as we iterate?
   - Who else should I talk to?
```

**Success Criteria**:
- 8/10 validate the pain exists
- 6/10 say they would use our solution
- 5/10 say pricing is reasonable
- 3/10 request early access

---

### Ongoing Feedback Loop

**After Launch**:
- Weekly user interviews (2-3 per week)
- NPS surveys (monthly)
- In-app feedback widget
- Support ticket analysis
- Churn interviews (why did they leave?)

**Insights ‚Üí Action**:
- Track common feature requests ‚Üí roadmap prioritization
- Track objections ‚Üí update messaging
- Track usage patterns ‚Üí optimize onboarding
- Track churn reasons ‚Üí fix retention issues

---

## 8. Data-Driven Decision Framework

### Experiment Tracking

**For every major decision, run experiments**:

**Example: Landing Page CTA**
```
Hypothesis: "Start Free Trial" CTA converts better than "Get Early Access"

Test: A/B test with 50/50 traffic split
Duration: 1 week or 1000 visitors (whichever first)
Success Metric: Click-through rate

Results:
- Variant A ("Start Free Trial"): 12% CTR
- Variant B ("Get Early Access"): 15% CTR
- Winner: Variant B (+25% lift)

Action: Adopt "Get Early Access" as default CTA
```

**Test Ideas** (prioritized):
1. Landing page headline variants
2. Pricing page format (table vs. cards)
3. Demo video vs. interactive demo
4. Onboarding flow (steps, copy, CTAs)
5. Email sequences (timing, content)

---

### Weekly Data Review

**Every Monday Morning**:
1. Pull key metrics from dashboards
2. Update REVENUE_TRACKING.md
3. Identify anomalies (spikes, drops)
4. Generate insights and hypotheses
5. Share summary with team
6. Adjust strategy as needed

**Template**:
```markdown
## Week [N] Data Review

### Headlines
- MRR: $X (+$Y from last week)
- New Customers: N (+M)
- Churn: P (-Q)
- Top Source: [Channel] (X% of signups)

### Insights
- [Finding 1]: [Data] suggests [interpretation]
- [Finding 2]: [Trend] indicates [opportunity/risk]

### Actions
- [ ] Action item based on data
- [ ] Test hypothesis X
- [ ] Fix issue Y
```

---

## 9. Recommendations & Next Steps

### Immediate Actions (This Week)

**Gray (Data Engineer) - Personal Assignments**:

1. **Set up Analytics Infrastructure** (4 hours)
   - [ ] Install Plausible analytics on landing page
   - [ ] Configure PostHog for event tracking
   - [ ] Create analytics database schema
   - [ ] Set up Stripe webhook listener for revenue events

2. **Competitive Deep Dive** (4 hours)
   - [ ] Create accounts for LangSmith, n8n, AutoGPT
   - [ ] Test onboarding flows, note friction points
   - [ ] Screenshot pricing pages, save to archive
   - [ ] Document feature comparison matrix

3. **User Research Prep** (3 hours)
   - [ ] Finalize interview script
   - [ ] Recruit 10 interview candidates (personal network + Twitter DMs)
   - [ ] Schedule interviews for next week
   - [ ] Set up recording/transcription (Otter.ai)

4. **Revenue Dashboard** (3 hours)
   - [ ] Create Google Sheet for daily metrics tracking
   - [ ] Set up formulas for MRR, churn, conversion rates
   - [ ] Build simple charts for weekly team review
   - [ ] Share with team for feedback

5. **Market Sizing Report** (2 hours)
   - [ ] Validate TAM/SAM/SOM numbers with research
   - [ ] Estimate realistic customer acquisition targets
   - [ ] Create 3 scenarios: conservative, base, aggressive
   - [ ] Present to Marcus for revenue planning

---

### Collaboration Points

**With Sable (Principal Engineer)**:
- Ensure event tracking is properly instrumented in backend
- Design analytics data schema together
- Plan API usage tracking for usage-based pricing

**With DeVonte (Full-Stack)**:
- Add analytics tracking to landing page and app
- Implement signup funnel instrumentation
- A/B testing framework for experiments

**With Yuki (SRE)**:
- Set up monitoring dashboards (Grafana + Prometheus)
- Ensure analytics infrastructure is scalable
- Plan data retention and archival strategy

**With Marcus (CEO)**:
- Weekly data review and insights sharing
- Customer interview findings and recommendations
- Pricing adjustments based on market feedback

---

## 10. Success Criteria

### Week 1 (This Week)
- ‚úÖ Analytics infrastructure deployed
- ‚úÖ Competitive analysis complete
- ‚úÖ User interviews scheduled (10)
- ‚úÖ Revenue dashboard operational
- ‚úÖ Market sizing validated

### Week 2 (Launch Week)
- ‚úÖ Real-time tracking of launch metrics
- ‚úÖ 5+ user interviews completed
- ‚úÖ Pricing validated with early customers
- ‚úÖ First conversion tracked and analyzed

### Week 6 (End of Initial Phase)
- ‚úÖ Comprehensive data on all key metrics
- ‚úÖ 30+ user interviews completed
- ‚úÖ Clear understanding of best acquisition channels
- ‚úÖ Data-driven product roadmap
- ‚úÖ Pricing optimization recommendations
- ‚úÖ Predictable customer acquisition model

---

## Conclusion

The market opportunity for AgentHQ is validated:
- **Clear pain point**: Multi-agent orchestration is genuinely difficult
- **Differentiated solution**: Visual interface + production infrastructure
- **Competitive pricing**: $49-$149/mo is well-positioned
- **Large TAM**: $2B+ market, growing rapidly
- **Multiple use cases**: Customer support, content, code review, research, sales

**Our competitive advantage**:
We're not just building another agent framework. We're building the **visual, production-ready orchestration layer** that makes multi-agent systems manageable. No one else has this combination of:
1. Visual real-time interface (isometric game view)
2. Production infrastructure (BullMQ, Redis, monitoring)
3. Claude Agent SDK integration
4. Hosted + self-hosted options

**From a data perspective**, we have everything we need to track our progress and optimize our go-to-market strategy. Now we execute.

---

**Next Update**: End of Week 1 (February 1, 2026)
**Questions?**: Contact Gray (@graham_sutton)

---

## Appendix: Resources

### Market Research Sources
- Gartner: AI/ML infrastructure market reports
- CB Insights: AI startup funding trends
- Product Hunt: AI tools launches and reception
- GitHub: Star counts, contributor activity
- Reddit: r/MachineLearning, r/artificial community discussions

### Analytics Tools Evaluated
| Tool | Use Case | Cost | Recommendation |
|------|----------|------|----------------|
| Plausible | Landing page analytics | Free (self-hosted) | ‚úÖ Use |
| PostHog | Product analytics | Free tier | ‚úÖ Use |
| Mixpanel | Event tracking | $25/mo | ‚è≥ Later |
| Amplitude | Product analytics | $49/mo | ‚è≥ Later |
| Stripe Dashboard | Revenue analytics | Free | ‚úÖ Use |
| ChartMogul | MRR analytics | $100/mo | ‚è≥ When we have budget |
| Google Sheets | Custom dashboards | Free | ‚úÖ Use |

### Useful Reading
- "The SaaS Metrics Bible" - ChartMogul
- "Mom Test" - Rob Fitzpatrick (user interview methodology)
- "Competing Against Luck" - Clayton Christensen (jobs-to-be-done)
- "Obviously Awesome" - April Dunford (positioning)
